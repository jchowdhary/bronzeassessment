{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: PDF Summarization using RAG with Open Source LLM\n",
    "\n",
    "## Objective\n",
    "This notebook demonstrates:\n",
    "- PDF document processing and text extraction\n",
    "- Creating embeddings and storing them in ChromaDB vector database\n",
    "- Using RAG (Retrieval Augmented Generation) with LangChain\n",
    "- Utilizing Groq API with open-source Llama model (instead of OpenAI)\n",
    "\n",
    "## Requirements\n",
    "- langchain\n",
    "- langchain-core\n",
    "- langchain-community\n",
    "- langchain-text-splitters\n",
    "- langchain-groq\n",
    "- chromadb\n",
    "- pypdf\n",
    "- sentence-transformers\n",
    "- python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a6371c93bc14e7a9ffe77522667d77c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# RetrievalQA can move between langchain versions — try common locations\n",
    "try:\n",
    "    from langchain.chains import RetrievalQA\n",
    "except Exception:\n",
    "    try:\n",
    "        from langchain.chains.retrieval_qa import RetrievalQA\n",
    "    except Exception:\n",
    "        RetrievalQA = None\n",
    "\n",
    "# PromptTemplate location may vary between langchain and langchain_core\n",
    "try:\n",
    "    from langchain.prompts import PromptTemplate\n",
    "except Exception:\n",
    "    try:\n",
    "        from langchain_core.prompts import PromptTemplate\n",
    "    except Exception:\n",
    "        PromptTemplate = None\n",
    "\n",
    "print(\"✅ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Environment Variables\n",
    "\n",
    "We load the GROQ API key from the .env file located in the parent directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GROQ API key loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from parent directory\n",
    "env_path = os.path.join('..', '.env')\n",
    "load_dotenv(env_path)\n",
    "\n",
    "# Get GROQ API key\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "if groq_api_key:\n",
    "    print(\"✅ GROQ API key loaded successfully\")\n",
    "else:\n",
    "    print(\"❌ GROQ API key not found. Please check your .env file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load and Process PDF Document\n",
    "\n",
    "We'll load the PDF from the dataset folder and extract its content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 1 page(s) from PDF\n",
      "\n",
      "First 500 characters of content:\n",
      "Artificial Intelligence and Machine Learning\n",
      "Introduction:\n",
      "Artificial Intelligence (AI) is revolutionizing how we interact with technology.\n",
      "Machine Learning, a subset of AI, enables computers to learn from data without\n",
      "explicit programming.\n",
      "Key Concepts:\n",
      "1. Supervised Learning: Training models with labeled data to make predictions.\n",
      "2. Unsupervised Learning: Finding patterns in unlabeled data.\n",
      "3. Deep Learning: Using neural networks with multiple layers for complex tasks.\n",
      "4. Natural Language Proc\n"
     ]
    }
   ],
   "source": [
    "# Define PDF path\n",
    "pdf_path = os.path.join('dataset', 'sample_document.pdf')\n",
    "\n",
    "# Load PDF\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"✅ Loaded {len(documents)} page(s) from PDF\")\n",
    "print(f\"\\nFirst 500 characters of content:\")\n",
    "print(documents[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Split Text into Chunks\n",
    "\n",
    "For better retrieval, we split the document into smaller chunks with overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Split document into 3 chunks\n",
      "\n",
      "Example chunk:\n",
      "Artificial Intelligence and Machine Learning\n",
      "Introduction:\n",
      "Artificial Intelligence (AI) is revolutionizing how we interact with technology.\n",
      "Machine Learning, a subset of AI, enables computers to learn from data without\n",
      "explicit programming.\n",
      "Key Concepts:\n",
      "1. Supervised Learning: Training models with labeled data to make predictions.\n",
      "2. Unsupervised Learning: Finding patterns in unlabeled data.\n",
      "3. Deep Learning: Using neural networks with multiple layers for complex tasks.\n"
     ]
    }
   ],
   "source": [
    "# Initialize text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,  # Size of each chunk\n",
    "    chunk_overlap=50,  # Overlap between chunks\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "# Split documents\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"✅ Split document into {len(chunks)} chunks\")\n",
    "print(f\"\\nExample chunk:\")\n",
    "print(chunks[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create Embeddings and Store in ChromaDB\n",
    "\n",
    "We use HuggingFace embeddings (open-source) and store them in ChromaDB vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_44467/1737110284.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "720957a345ff46d3809f4caa0d71edab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6795289f7ab74dfe8f7e6c11bc78ea5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4acdecaa93064fdf89dc651bdbdc5513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2cd5b536520491a97af017f9df76dd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bc84d5f14cd408cad53bde1fda9bf15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58ea33e2e9854aaab597837b941d6097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Embedding model loaded\n",
      "✅ Created ChromaDB with 3 document chunks\n",
      "   Vector store saved to: ./chroma_db\n",
      "✅ Created ChromaDB with 3 document chunks\n",
      "   Vector store saved to: ./chroma_db\n"
     ]
    }
   ],
   "source": [
    "# Initialize embedding model (using open-source HuggingFace model)\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "print(\"✅ Embedding model loaded\")\n",
    "\n",
    "# Create ChromaDB vector store\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"./chroma_db\"\n",
    ")\n",
    "\n",
    "print(f\"✅ Created ChromaDB with {len(chunks)} document chunks\")\n",
    "print(f\"   Vector store saved to: ./chroma_db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Initialize Open Source LLM (Groq with Llama)\n",
    "\n",
    "We use Groq API with the open-source Llama model instead of OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Groq LLM with Llama model initialized\n"
     ]
    }
   ],
   "source": [
    "# Initialize Groq LLM with latest Llama 3.2 text model (vision model decommissioned)\n",
    "llm = ChatGroq(\n",
    "    groq_api_key=groq_api_key,\n",
    "    model_name=\"llama-3.3-70b-versatile\",  # Latest Llama 3.2 text model\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "print(\"✅ Groq LLM with Llama model initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Create RAG Chain with Custom Prompt\n",
    "\n",
    "We set up a Retrieval QA chain that uses RAG to answer questions based on the PDF content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ RAG chain created successfully\n"
     ]
    }
   ],
   "source": [
    "# Create custom prompt template for summarization\n",
    "prompt_template = \"\"\"\n",
    "Use the following context from the document to answer the question.\n",
    "If you cannot find the answer in the context, say \"I cannot find this information in the document.\"\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "# Create retriever from vector store\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3}  # Retrieve top 3 most relevant chunks\n",
    ")\n",
    "\n",
    "# Create RetrievalQA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": PROMPT},\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "print(\"✅ RAG chain created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Generate Document Summary\n",
    "\n",
    "Now let's use our RAG system to summarize the PDF document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DOCUMENT SUMMARY\n",
      "================================================================================\n",
      "The document provides an overview of Artificial Intelligence (AI) and Machine Learning (ML), highlighting their potential to revolutionize various aspects of technology and society. The main topics covered include:\n",
      "\n",
      "1. **Introduction to AI and ML**: AI is introduced as a revolutionary technology, with ML as a subset that enables computers to learn from data without explicit programming.\n",
      "2. **Key Concepts**: The document outlines four key concepts:\n",
      "   - **Supervised Learning**: Training models with labeled data for predictions.\n",
      "   - **Unsupervised Learning**: Finding patterns in unlabeled data.\n",
      "   - **Deep Learning**: Utilizing neural networks with multiple layers for complex tasks.\n",
      "   - **Natural Language Processing**: Enabling computers to understand human language.\n",
      "3. **Applications**: AI and ML have various applications across industries, including:\n",
      "   - **Healthcare**: Disease diagnosis and drug discovery.\n",
      "   - **Finance**: Fraud detection and algorithmic trading.\n",
      "   - **Transportation**: Autonomous vehicles and route optimization.\n",
      "   - **Education**: Personalized learning and intelligent tutoring systems.\n",
      "4. **Challenges**: Despite progress, AI faces challenges such as data privacy, algorithmic bias, interpretability, and ethical considerations.\n",
      "5. **Conclusion**: The document concludes that AI and ML are transforming industries, creating new opportunities, and promising to solve complex problems and enhance human capabilities in unprecedented ways. Researchers are working towards developing more transparent and responsible AI systems.\n",
      "\n",
      "Overall, the document presents a broad view of AI and ML, covering their fundamental concepts, applications, challenges, and the future potential of these technologies to impact society positively.\n",
      "\n",
      "================================================================================\n",
      "Sources used: 3 document chunks\n"
     ]
    }
   ],
   "source": [
    "# Query for summarization\n",
    "query = \"Provide a comprehensive summary of this document, including main topics, key concepts, and conclusions.\"\n",
    "\n",
    "# Get response from RAG chain\n",
    "result = qa_chain.invoke({\"query\": query})\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DOCUMENT SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(result['result'])\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Sources used: {len(result['source_documents'])} document chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Ask Specific Questions\n",
    "\n",
    "Let's test the RAG system with specific questions about the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Question 1: What are the key concepts discussed in this document?\n",
      "================================================================================\n",
      "\n",
      "Answer:\n",
      "The key concepts discussed in this document are:\n",
      "\n",
      "1. Supervised Learning: Training models with labeled data to make predictions.\n",
      "2. Unsupervised Learning: Finding patterns in unlabeled data.\n",
      "3. Deep Learning: Using neural networks with multiple layers for complex tasks.\n",
      "4. Natural Language Processing: Enabling computers to understand human language.\n",
      "\n",
      "Relevant chunks used: 3\n",
      "\n",
      "================================================================================\n",
      "Question 2: What are the applications of AI mentioned?\n",
      "================================================================================\n",
      "\n",
      "Answer:\n",
      "The key concepts discussed in this document are:\n",
      "\n",
      "1. Supervised Learning: Training models with labeled data to make predictions.\n",
      "2. Unsupervised Learning: Finding patterns in unlabeled data.\n",
      "3. Deep Learning: Using neural networks with multiple layers for complex tasks.\n",
      "4. Natural Language Processing: Enabling computers to understand human language.\n",
      "\n",
      "Relevant chunks used: 3\n",
      "\n",
      "================================================================================\n",
      "Question 2: What are the applications of AI mentioned?\n",
      "================================================================================\n",
      "\n",
      "Answer:\n",
      "The applications of AI mentioned are:\n",
      "\n",
      "1. Healthcare: Disease diagnosis and drug discovery\n",
      "2. Finance: Fraud detection and algorithmic trading\n",
      "3. Transportation: Autonomous vehicles and route optimization\n",
      "4. Education: Personalized learning and intelligent tutoring systems\n",
      "\n",
      "Relevant chunks used: 3\n",
      "\n",
      "================================================================================\n",
      "Question 3: What challenges does AI face according to the document?\n",
      "================================================================================\n",
      "\n",
      "Answer:\n",
      "The applications of AI mentioned are:\n",
      "\n",
      "1. Healthcare: Disease diagnosis and drug discovery\n",
      "2. Finance: Fraud detection and algorithmic trading\n",
      "3. Transportation: Autonomous vehicles and route optimization\n",
      "4. Education: Personalized learning and intelligent tutoring systems\n",
      "\n",
      "Relevant chunks used: 3\n",
      "\n",
      "================================================================================\n",
      "Question 3: What challenges does AI face according to the document?\n",
      "================================================================================\n",
      "\n",
      "Answer:\n",
      "According to the document, AI faces challenges including:\n",
      "\n",
      "1. Data privacy\n",
      "2. Algorithmic bias\n",
      "3. Interpretability\n",
      "4. Ethical considerations.\n",
      "\n",
      "Relevant chunks used: 3\n",
      "\n",
      "Answer:\n",
      "According to the document, AI faces challenges including:\n",
      "\n",
      "1. Data privacy\n",
      "2. Algorithmic bias\n",
      "3. Interpretability\n",
      "4. Ethical considerations.\n",
      "\n",
      "Relevant chunks used: 3\n"
     ]
    }
   ],
   "source": [
    "# Example questions\n",
    "questions = [\n",
    "    \"What are the key concepts discussed in this document?\",\n",
    "    \"What are the applications of AI mentioned?\",\n",
    "    \"What challenges does AI face according to the document?\"\n",
    "]\n",
    "\n",
    "for i, question in enumerate(questions, 1):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Question {i}: {question}\")\n",
    "    print('='*80)\n",
    "    \n",
    "    result = qa_chain.invoke({\"query\": question})\n",
    "    print(f\"\\nAnswer:\\n{result['result']}\")\n",
    "    print(f\"\\nRelevant chunks used: {len(result['source_documents'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: View Retrieved Context\n",
    "\n",
    "Let's examine what content was retrieved from the vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 3 relevant chunks for query: 'What are the applications of AI?'\n",
      "\n",
      "Chunk 1:\n",
      "--------------------------------------------------------------------------------\n",
      "Artificial Intelligence and Machine Learning\n",
      "Introduction:\n",
      "Artificial Intelligence (AI) is revolutionizing how we interact with technology.\n",
      "Machine Learning, a subset of AI, enables computers to learn from data without\n",
      "explicit programming.\n",
      "Key Concepts:\n",
      "1. Supervised Learning: Training models with labeled data to make predictions.\n",
      "2. Unsupervised Learning: Finding patterns in unlabeled data.\n",
      "3. Deep Learning: Using neural networks with multiple layers for complex tasks.\n",
      "\n",
      "\n",
      "Chunk 2:\n",
      "--------------------------------------------------------------------------------\n",
      "are working to develop more transparent and responsible AI systems.\n",
      "Conclusion:\n",
      "AI and ML continue to transform industries and create new opportunities.\n",
      "As these technologies evolve, they promise to solve complex problems and\n",
      "enhance human capabilities in unprecedented ways.\n",
      "\n",
      "\n",
      "Chunk 3:\n",
      "--------------------------------------------------------------------------------\n",
      "4. Natural Language Processing: Enabling computers to understand human language.\n",
      "Applications:\n",
      "- Healthcare: Disease diagnosis and drug discovery\n",
      "- Finance: Fraud detection and algorithmic trading\n",
      "- Transportation: Autonomous vehicles and route optimization\n",
      "- Education: Personalized learning and intelligent tutoring systems\n",
      "Challenges:\n",
      "Despite significant progress, AI faces challenges including data privacy,\n",
      "algorithmic bias, interpretability, and ethical considerations. Researchers\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform a similarity search\n",
    "test_query = \"What are the applications of AI?\"\n",
    "relevant_docs = vectorstore.similarity_search(test_query, k=3)\n",
    "\n",
    "print(f\"\\nTop {len(relevant_docs)} relevant chunks for query: '{test_query}'\\n\")\n",
    "\n",
    "for i, doc in enumerate(relevant_docs, 1):\n",
    "    print(f\"Chunk {i}:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(doc.page_content)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What We Accomplished:\n",
    "\n",
    "1. **PDF Processing**: Loaded and extracted text from a PDF document\n",
    "2. **Text Chunking**: Split the document into manageable chunks for better retrieval\n",
    "3. **Embeddings**: Created vector embeddings using HuggingFace's sentence transformers (open-source)\n",
    "4. **Vector Database**: Stored embeddings in ChromaDB for efficient similarity search\n",
    "5. **Open Source LLM**: Used Groq API with Llama 3.1 model instead of OpenAI\n",
    "6. **RAG Implementation**: Built a Retrieval Augmented Generation system using LangChain\n",
    "7. **Summarization**: Generated summaries and answered questions about the PDF content\n",
    "\n",
    "### Key Technologies Used:\n",
    "- **LangChain**: Framework for LLM applications\n",
    "- **ChromaDB**: Open-source vector database\n",
    "- **Groq + Llama**: Open-source LLM (alternative to OpenAI)\n",
    "- **HuggingFace Embeddings**: Open-source embedding model\n",
    "- **RAG**: Retrieval Augmented Generation pattern"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
