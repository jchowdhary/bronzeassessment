{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Assignment 4: LLM + LangChain + MongoDB NoSQL Integration\n",
    "## Objective: Create a toolchain with LLM, LangChain, and MongoDB to store and query documents through an LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## Setup: Load Dependencies and Initialize MongoDB Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì All dependencies imported successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pymongo import MongoClient\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Print confirmation\n",
    "print(\"‚úì All dependencies imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mongodb_config",
   "metadata": {},
   "source": [
    "## MongoDB Configuration and Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "mongo_setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Connected to MongoDB at mongodb://localhost:27017\n",
      "‚úì Using database: assignment4_db\n",
      "‚úì Collections: documents, queries\n"
     ]
    }
   ],
   "source": [
    "# MongoDB Connection Configuration\n",
    "MONGODB_URI = os.getenv(\"MONGODB_URI\", \"mongodb://localhost:27017\")\n",
    "DATABASE_NAME = \"assignment4_db\"\n",
    "DOCUMENTS_COLLECTION = \"documents\"\n",
    "QUERIES_COLLECTION = \"queries\"\n",
    "\n",
    "# Create MongoDB client\n",
    "try:\n",
    "    mongo_client = MongoClient(MONGODB_URI, serverSelectionTimeoutMS=5000)\n",
    "    # Test connection\n",
    "    mongo_client.admin.command('ping')\n",
    "    print(f\"‚úì Connected to MongoDB at {MONGODB_URI}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error connecting to MongoDB: {e}\")\n",
    "    print(f\"Make sure MongoDB is running and accessible at {MONGODB_URI}\")\n",
    "\n",
    "# Get database\n",
    "db = mongo_client[DATABASE_NAME]\n",
    "\n",
    "# Get or create collections\n",
    "docs_collection = db[DOCUMENTS_COLLECTION]\n",
    "queries_collection = db[QUERIES_COLLECTION]\n",
    "\n",
    "# Create indexes for better query performance\n",
    "docs_collection.create_index([(\"document_id\", 1)])\n",
    "docs_collection.create_index([(\"source\", 1)])\n",
    "queries_collection.create_index([(\"timestamp\", -1)])\n",
    "\n",
    "print(f\"‚úì Using database: {DATABASE_NAME}\")\n",
    "print(f\"‚úì Collections: {DOCUMENTS_COLLECTION}, {QUERIES_COLLECTION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "llm_setup",
   "metadata": {},
   "source": [
    "## Initialize LLM and Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "llm_init",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Google LLM initialized\n",
      "‚úì SentenceTransformer embedding model loaded\n"
     ]
    }
   ],
   "source": [
    "# Initialize Google LLM (same as capstone1)\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "google_llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    temperature=0,\n",
    "    google_api_key=google_api_key\n",
    ")\n",
    "\n",
    "# Initialize Embedding Model\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "print(\"‚úì Google LLM initialized\")\n",
    "print(\"‚úì SentenceTransformer embedding model loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_documents",
   "metadata": {},
   "source": [
    "## Load and Process PDF Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "document_loading",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 899 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Loaded 117 pages from PDF\n",
      "‚úì Created 122 chunks from documents\n"
     ]
    }
   ],
   "source": [
    "# Load PDF document (same as capstone1)\n",
    "try:\n",
    "    loader = PyPDFLoader(\"dataset/AI Agents guidebook.pdf\")\n",
    "    documents = loader.load()\n",
    "    print(f\"‚úì Loaded {len(documents)} pages from PDF\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå PDF file not found. Using sample text data instead.\")\n",
    "    documents = []\n",
    "    sample_texts = [\n",
    "        \"Multi-agent systems consist of multiple intelligent agents that interact to solve complex problems.\",\n",
    "        \"AI agents use reasoning and planning to accomplish tasks autonomously.\",\n",
    "        \"Deep research systems combine web search, analysis, and report generation in multi-agent workflows.\"\n",
    "    ]\n",
    "    from langchain_core.documents import Document\n",
    "    documents = [Document(page_content=text, metadata={\"source\": \"sample_data\", \"page\": i}) \n",
    "                 for i, text in enumerate(sample_texts)]\n",
    "\n",
    "# Split documents into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=300\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "print(f\"‚úì Created {len(chunks)} chunks from documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embed_chunks",
   "metadata": {},
   "source": [
    "## Embed Chunks and Store in MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "embedding_storage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding chunks...\n",
      "‚úì Encoded 122 chunks\n",
      "‚úì Stored 122 documents in MongoDB\n",
      "‚úì Embedding dimension: 384 dimensions\n"
     ]
    }
   ],
   "source": [
    "# Encode chunks using embedding model\n",
    "print(\"Encoding chunks...\")\n",
    "encoded_chunks = [embedding_model.encode(chunk.page_content) for chunk in chunks]\n",
    "print(f\"‚úì Encoded {len(encoded_chunks)} chunks\")\n",
    "\n",
    "# Clear existing documents\n",
    "docs_collection.delete_many({})\n",
    "\n",
    "# Store chunks with embeddings in MongoDB\n",
    "documents_to_insert = []\n",
    "for i, chunk in enumerate(chunks):\n",
    "    doc = {\n",
    "        \"document_id\": f\"chunk_{i}\",\n",
    "        \"content\": chunk.page_content,\n",
    "        \"embedding\": encoded_chunks[i].tolist(),  # Store as list for MongoDB\n",
    "        \"source\": chunk.metadata.get(\"source\", \"unknown\"),\n",
    "        \"page\": chunk.metadata.get(\"page\", 0),\n",
    "        \"chunk_index\": i,\n",
    "        \"created_at\": datetime.utcnow()\n",
    "    }\n",
    "    documents_to_insert.append(doc)\n",
    "\n",
    "# Insert all documents\n",
    "result = docs_collection.insert_many(documents_to_insert)\n",
    "print(f\"‚úì Stored {len(result.inserted_ids)} documents in MongoDB\")\n",
    "print(f\"‚úì Embedding dimension: {len(encoded_chunks[0])} dimensions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "query_function",
   "metadata": {},
   "source": [
    "## Semantic Search Function with MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "mongo_search",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üîç Search Results for: What are AI agents?\n",
      "================================================================================\n",
      "\n",
      "Result 1:\n",
      "Similarity: 0.7394\n",
      "Source: dataset/AI Agents guidebook.pdf (Page 34)\n",
      "Content: DailyDoseofDS.com \n",
      " \n",
      " \n",
      "AI Agents \n",
      "Projects  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "34...\n",
      "\n",
      "Result 2:\n",
      "Similarity: 0.7243\n",
      "Source: dataset/AI Agents guidebook.pdf (Page 7)\n",
      "Content: DailyDoseofDS.com \n",
      " \n",
      " \n",
      "Here, the AI agents not only execute the research process end-to-end but also \n",
      "self-reÔ¨Åne their outputs, ensuring the Ô¨Ånal report is comprehensive, up-to-date, \n",
      "and well-structu...\n",
      "\n",
      "Result 3:\n",
      "Similarity: 0.6910\n",
      "Source: dataset/AI Agents guidebook.pdf (Page 4)\n",
      "Content: DailyDoseofDS.com \n",
      " \n",
      " \n",
      "AI Agents  \n",
      " \n",
      "4...\n"
     ]
    }
   ],
   "source": [
    "def search_mongodb(query_text, top_k=3):\n",
    "    \"\"\"\n",
    "    Search MongoDB documents using semantic similarity\n",
    "    \"\"\"\n",
    "    # Encode the query\n",
    "    query_embedding = embedding_model.encode(query_text)\n",
    "    query_embedding_list = query_embedding.tolist()\n",
    "    \n",
    "    # Retrieve all documents and calculate similarity\n",
    "    all_docs = list(docs_collection.find({}, {\"embedding\": 1, \"content\": 1, \"source\": 1, \"page\": 1, \"_id\": 0}))\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    similarities = []\n",
    "    for doc in all_docs:\n",
    "        doc_embedding = np.array(doc[\"embedding\"])\n",
    "        query_emb = np.array(query_embedding_list)\n",
    "        \n",
    "        # Cosine similarity\n",
    "        similarity = np.dot(doc_embedding, query_emb) / (np.linalg.norm(doc_embedding) * np.linalg.norm(query_emb))\n",
    "        similarities.append({\n",
    "            \"content\": doc[\"content\"],\n",
    "            \"source\": doc[\"source\"],\n",
    "            \"page\": doc[\"page\"],\n",
    "            \"similarity\": float(similarity)\n",
    "        })\n",
    "    \n",
    "    # Sort by similarity and get top_k\n",
    "    similarities.sort(key=lambda x: x[\"similarity\"], reverse=True)\n",
    "    results = similarities[:top_k]\n",
    "    \n",
    "    return results, query_embedding\n",
    "\n",
    "# Test the search function\n",
    "test_query = \"What are AI agents?\"\n",
    "results, query_emb = search_mongodb(test_query, top_k=3)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"üîç Search Results for: {test_query}\")\n",
    "print(f\"{'='*80}\")\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"\\nResult {i}:\")\n",
    "    print(f\"Similarity: {result['similarity']:.4f}\")\n",
    "    print(f\"Source: {result['source']} (Page {result['page']})\")\n",
    "    print(f\"Content: {result['content'][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "llm_query",
   "metadata": {},
   "source": [
    "## Query Documents through LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "llm_response",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìù LLM Response\n",
      "================================================================================\n",
      "Query: Explain the concept of multi-agent systems and their workflow\n",
      "\n",
      "Response:\n",
      "Multi-agent systems involve several agents, each with a specific role and task, that work together to achieve a final outcome. These agents can also access tools to complete their tasks. In a multi-agent system, collaboration and feedback exchange are crucial for optimal performance. Instead of a single agent handling all responsibilities, a team of specialized agents can divide tasks and enhance each other's outputs.\n",
      "\n",
      "The workflow of a multi-agent system can be structured with a manager agent that coordinates multiple sub-agents and iteratively decides on the next steps. Humans can define the hierarchy between agents, their roles, and the tools they can access.\n",
      "\n",
      "An example of a multi-agent system in action is an AI-powered financial analysis system. In this scenario:\n",
      "*   One agent is responsible for gathering data.\n",
      "*   Another agent assesses risk.\n",
      "*   A third agent builds the strategy.\n",
      "*   A fourth agent writes the report.\n",
      "\n",
      "This collaborative approach leads to smarter and more accurate results. The best practice for enabling agent collaboration is to design workflows where agents can exchange insights and refine their responses collectively.\n"
     ]
    }
   ],
   "source": [
    "def query_with_llm(user_query, top_k=3):\n",
    "    \"\"\"\n",
    "    Search MongoDB and generate LLM response using retrieved context\n",
    "    \"\"\"\n",
    "    # Search for relevant documents\n",
    "    search_results, query_embedding = search_mongodb(user_query, top_k=top_k)\n",
    "    \n",
    "    # Build context from search results\n",
    "    context_text = \"\\n\\n\".join([\n",
    "        f\"Context {i+1} (Source: {result['source']}, Similarity: {result['similarity']:.4f}):\\n{result['content']}\"\n",
    "        for i, result in enumerate(search_results)\n",
    "    ])\n",
    "    \n",
    "    # Create prompt\n",
    "    prompt_template = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are an expert assistant that answers questions based on provided context.\n",
    "\n",
    "Context Information:\n",
    "{context}\n",
    "\n",
    "User Question: {question}\n",
    "\n",
    "Please provide a comprehensive answer based on the context above. If the context doesn't contain relevant information, indicate that.\n",
    "\"\"\")\n",
    "    \n",
    "    # Generate response\n",
    "    chain = prompt_template | google_llm | StrOutputParser()\n",
    "    response = chain.invoke({\n",
    "        \"context\": context_text,\n",
    "        \"question\": user_query\n",
    "    })\n",
    "    \n",
    "    return {\n",
    "        \"query\": user_query,\n",
    "        \"response\": response,\n",
    "        \"search_results\": search_results,\n",
    "        \"context\": context_text\n",
    "    }\n",
    "\n",
    "# Example query\n",
    "user_query = \"Explain the concept of multi-agent systems and their workflow\"\n",
    "result = query_with_llm(user_query, top_k=3)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"üìù LLM Response\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Query: {result['query']}\\n\")\n",
    "print(f\"Response:\\n{result['response']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "store_query",
   "metadata": {},
   "source": [
    "## Store Query Results in MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "save_query_results",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Query saved to MongoDB\n",
      "  Query ID: query_1768459835.772808\n",
      "  Timestamp: 2026-01-15 12:20:35.772824\n",
      "  Search Results Used: 3\n",
      "  Top Similarity: 0.7127\n"
     ]
    }
   ],
   "source": [
    "# Store the query and response in MongoDB\n",
    "query_document = {\n",
    "    \"query_id\": f\"query_{datetime.utcnow().timestamp()}\",\n",
    "    \"query_text\": user_query,\n",
    "    \"llm_response\": result[\"response\"],\n",
    "    \"search_results_count\": len(result[\"search_results\"]),\n",
    "    \"top_similarity_score\": result[\"search_results\"][0][\"similarity\"] if result[\"search_results\"] else 0,\n",
    "    \"timestamp\": datetime.utcnow(),\n",
    "    \"context_summary\": f\"Retrieved {len(result['search_results'])} relevant documents\"\n",
    "}\n",
    "\n",
    "insert_result = queries_collection.insert_one(query_document)\n",
    "print(f\"\\n‚úì Query saved to MongoDB\")\n",
    "print(f\"  Query ID: {query_document['query_id']}\")\n",
    "print(f\"  Timestamp: {query_document['timestamp']}\")\n",
    "print(f\"  Search Results Used: {query_document['search_results_count']}\")\n",
    "print(f\"  Top Similarity: {query_document['top_similarity_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retrieve_history",
   "metadata": {},
   "source": [
    "## Retrieve Query History from MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "query_history",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìö Query History from MongoDB\n",
      "================================================================================\n",
      "Total queries stored: 1\n",
      "\n",
      "Query 1:\n",
      "  Query Text: Explain the concept of multi-agent systems and their workflow\n",
      "  Timestamp: 2026-01-15 12:20:35.772000\n",
      "  Search Results Count: 3\n",
      "  Top Similarity Score: 0.7127\n",
      "  Response Preview: Multi-agent systems involve several agents, each with a specific role and task, that work together t...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Retrieve all stored queries from MongoDB\n",
    "all_queries = list(queries_collection.find({}).sort(\"timestamp\", -1).limit(5))\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"üìö Query History from MongoDB\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Total queries stored: {queries_collection.count_documents({})}\\n\")\n",
    "\n",
    "for i, query_doc in enumerate(all_queries, 1):\n",
    "    print(f\"Query {i}:\")\n",
    "    print(f\"  Query Text: {query_doc.get('query_text')}\")\n",
    "    print(f\"  Timestamp: {query_doc.get('timestamp')}\")\n",
    "    print(f\"  Search Results Count: {query_doc.get('search_results_count')}\")\n",
    "    print(f\"  Top Similarity Score: {query_doc.get('top_similarity_score'):.4f}\")\n",
    "    print(f\"  Response Preview: {query_doc.get('llm_response')[:100]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistics",
   "metadata": {},
   "source": [
    "## Database Statistics and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db_stats",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìä MongoDB Database Statistics\n",
      "================================================================================\n",
      "Database Name: assignment4_db\n",
      "MongoDB URI: mongodb://localhost:27017\n",
      "\n",
      "Collections:\n",
      "  - documents: 122 documents\n",
      "  - queries: 1 queries\n",
      "\n",
      "Embedding Model: SentenceTransformer (all-MiniLM-L6-v2)\n",
      "Embedding Dimension: 384 dimensions\n",
      "\n",
      "LLM Model: Google Generative AI (Gemini 2.5 Flash Lite)\n",
      "\n",
      "‚úì Assignment 4 completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Get database statistics\n",
    "documents_count = docs_collection.count_documents({})\n",
    "queries_count = queries_collection.count_documents({})\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"üìä MongoDB Database Statistics\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Database Name: {DATABASE_NAME}\")\n",
    "print(f\"MongoDB URI: {MONGODB_URI}\")\n",
    "print(f\"\\nCollections:\")\n",
    "print(f\"  - {DOCUMENTS_COLLECTION}: {documents_count} documents\")\n",
    "print(f\"  - {QUERIES_COLLECTION}: {queries_count} queries\")\n",
    "print(f\"\\nEmbedding Model: SentenceTransformer (all-MiniLM-L6-v2)\")\n",
    "print(f\"Embedding Dimension: {len(encoded_chunks[0])} dimensions\")\n",
    "print(f\"\\nLLM Model: Google Generative AI (Gemini 2.5 Flash Lite)\")\n",
    "print(f\"\\n‚úì Assignment 4 completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced_queries",
   "metadata": {},
   "source": [
    "## Advanced: Multiple Query Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "multiple_queries",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Query: What is deep research and how does it work?\n",
      "================================================================================\n",
      "\n",
      "Response:\n",
      "Deep research, as described in the provided context, is a feature that helps users obtain detailed insights on any topic. It involves a multi-agent system that automates the research process.\n",
      "\n",
      "Here's how it works based on the context:\n",
      "\n",
      "1.  **User Query:** The process begins with the user submitting a query.\n",
      "2.  **Deep Web Search:** A web search agent then conducts a deep web search using a platform called Linkup.\n",
      "3.  **Verification and Deduplication:** A research analyst agent verifies the searc...\n",
      "\n",
      "‚úì Query stored in MongoDB\n",
      "\n",
      "================================================================================\n",
      "Query: How do agents collaborate in multi-agent systems?\n",
      "================================================================================\n",
      "\n",
      "Response:\n",
      "In multi-agent systems, agents collaborate by exchanging feedback and working together to achieve a common goal. Instead of a single agent performing all tasks, specialized agents can divide responsibilities and enhance each other's outputs. This is exemplified in an AI-powered financial analysis system where one agent gathers data, another assesses risk, a third builds strategy, and a fourth writes the report. The best practice for enabling this collaboration is to design workflows that allow a...\n",
      "\n",
      "‚úì Query stored in MongoDB\n"
     ]
    }
   ],
   "source": [
    "# Test multiple queries\n",
    "test_queries = [\n",
    "    \"What is deep research and how does it work?\",\n",
    "    \"How do agents collaborate in multi-agent systems?\"\n",
    "]\n",
    "\n",
    "for test_q in test_queries:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Query: {test_q}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    result = query_with_llm(test_q, top_k=2)\n",
    "    \n",
    "    print(f\"\\nResponse:\\n{result['response'][:500]}...\\n\")\n",
    "    \n",
    "    # Store in MongoDB\n",
    "    query_document = {\n",
    "        \"query_id\": f\"query_{datetime.utcnow().timestamp()}\",\n",
    "        \"query_text\": test_q,\n",
    "        \"llm_response\": result[\"response\"],\n",
    "        \"search_results_count\": len(result[\"search_results\"]),\n",
    "        \"top_similarity_score\": result[\"search_results\"][0][\"similarity\"] if result[\"search_results\"] else 0,\n",
    "        \"timestamp\": datetime.utcnow(),\n",
    "        \"context_summary\": f\"Retrieved {len(result['search_results'])} relevant documents\"\n",
    "    }\n",
    "    queries_collection.insert_one(query_document)\n",
    "    print(f\"‚úì Query stored in MongoDB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleanup",
   "metadata": {},
   "source": [
    "## Cleanup: Close MongoDB Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "close_connection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì MongoDB connection closed\n",
      "\n",
      "‚úì Assignment 4 completed successfully!\n",
      "\n",
      "Summary:\n",
      "  - Loaded and processed PDF documents\n",
      "  - Created embeddings with SentenceTransformer\n",
      "  - Stored 122 documents in MongoDB\n",
      "  - Processed 1 queries through LLM\n",
      "  - Used Google Generative AI for LLM responses\n",
      "  - Implemented semantic search with MongoDB\n"
     ]
    }
   ],
   "source": [
    "# Close MongoDB connection\n",
    "mongo_client.close()\n",
    "print(\"‚úì MongoDB connection closed\")\n",
    "print(\"\\n‚úì Assignment 4 completed successfully!\")\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"  - Loaded and processed PDF documents\")\n",
    "print(f\"  - Created embeddings with SentenceTransformer\")\n",
    "print(f\"  - Stored {documents_count} documents in MongoDB\")\n",
    "print(f\"  - Processed {queries_count} queries through LLM\")\n",
    "print(f\"  - Used Google Generative AI for LLM responses\")\n",
    "print(f\"  - Implemented semantic search with MongoDB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
